{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Tutorial - Remote Arrow\n",
    "\n",
    "This notebook serves as an interactive tutorial (and documentation) to **Remote Arrow**.\n",
    "More broadly it introduces you to **Apache Arrow** and **Apache Arrow Flight**.\n",
    "\n",
    "**Apache Arrow** is a language-independent columnar memory format for flat and hierarchical data. <br>\n",
    "It became increasingly popular for big data applications because of its high performance and efficacy in handling tabular data, <br>\n",
    "as well as its rich eco-system of 3rd-party libraries. <br>\n",
    "\n",
    "**Apache Arrow Flight** is a framework for high-speed transmission of Apache Arrow Tables.  <br>\n",
    "It achieves that by eliminating the overhead for (de)serialization of the data and allowing parallel data streaming. <br>\n",
    "Arrow Flight defines a set of protocols and interfaces that enables a language and platform agnostic approach to sharing data. <br>\n",
    "\n",
    "**Remote Arrow** is a **custom** framework built on top of Apache Arrow Flight and aims to solve the problem of redundancy <br>\n",
    "and performance bottlenecks when common or shared datasets have to be accessed by multiple clients. <br>\n",
    "It does so by outsourcing the ownership and computational burden to a centralized server and allowing clients to access the data through remote queries. <br>\n",
    "Each query result requested by a client is subsequently made available to all other clients. This is also true for new datasets uploaded by a client. <br>\n",
    "\n",
    "This eliminates the need for data transfers between clients, redudant computation of complex queries, or unnecessary storage of potentially large data. <br>\n",
    "\n",
    "\n",
    "You can learn more by reading through the *README* and sources listed below:\n",
    "#### Sources:\n",
    "\n",
    "1. [Apache Arrow](https://arrow.apache.org/ \"Apache Arrow\")\n",
    "2. [Introducing Apache Arrow Flight](https://arrow.apache.org/blog/2019/10/13/introducing-arrow-flight/ \"Introducing Apache Arrow Flight\") \n",
    "3. [Apache Arrow Flight API](https://arrow.apache.org/docs/format/Flight.html \"Apache Arrow Flight API\") \n",
    "4. [Benchmarking Apache Arrow Flight (Tanveer Ahmad, Zaid Al Ars and H. Peter Hofstee)](https://arxiv.org/pdf/2204.03032.pdf) \n",
    "5. [Apache Arrow Zero Memory Copy](https://towardsdatascience.com/apache-arrow-read-dataframe-with-zero-memory-69634092b1a)\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Run this cell only if you're not using the Docker container: hoangln1/remote-arrow:tutorial\n",
    "!pip3 install pandas\n",
    "!pip3 install pyarrow==9.0.0\n",
    "\n",
    "# Download the csv file\n",
    "!pip3 install gdown\n",
    "!gdown --id \"1Ko0pE194OMvFH0Vp_AJIBXvezF6B9NKY\"\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Arrow Table\n",
    "Let's take a look at **the Arrow Table** format by loading a CSV file:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\n",
    "import pyarrow as pa\n",
    "import pyarrow.csv as csv\n",
    "\n",
    "table = csv.read_csv('hawaii_covid.csv')\n",
    "print(table.schema)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Arrow Tables support a variety of common functions for handling tabular data, such as **join**, **sort_by**, **group_by**, **drop**, **select** or **take**:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "table.select([5]) # Get column at index 5"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "table.num_rows"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "If you're familiar with **pandas** and/or **SQL** it may come to you as a relieve that **Arrow Table** provides similar methods and APIs. <br>\n",
    "When in doubt, you can always convert Arrow Tables into pandas dataframes."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "table.take([0, 1, 2]).to_pandas() # Get row 0, 1, and 2 and convert to pandas df"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### **So why all the trouble with Arrow?**\n",
    "On one hand Arrow stores the data in **columnar** format which makes a lot of computational routines substantially faster,<br>\n",
    "especially when iterating through large chunks of data. That is, because a columns are stored in contiguous memory, <br>\n",
    "which is exceedingly easier to read in chunks compared to row-based memory layouts, as illustrated here [4]: <br>\n",
    "\n",
    "![image](https://arrow.apache.org/img/simd.png)\n",
    "\n",
    "Secondly, it provides a language-agnostic way to pass tabular data from one application to another. <br>\n",
    "Last but not least, it also allows for a technique called zero-copy reads. <br>\n",
    "Instead of copying the data and passing it from one application to another, <br>\n",
    "we can simply pass a pointer to the location in memory [5]. <br>\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "So far, we have uploaded and modified our dataset only locally. <br> \n",
    "Let's see how we can make them accessible to other clients."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Starting the server\n",
    "Remote Arrow uses one server to manage datasets and exposes a fixed set of commands (upload, download, query) to all clients in the network. <br>\n",
    "This set of commands can, however, be extended and adapted depending on your specific needs. <br>\n",
    "\n",
    "As mentioned before, Remote Arrow uses the **Apache Arrow Flight API** which specifies a list of services that need to be supported (e.g. **doGet**, **doPut**, **doAction**). <br>\n",
    "This is reminiscent of the **REST** architecture style (**PUT**, **POST**, **DELETE**, **GET**). <br> \n",
    "The bottomline is that both simply define a uniform interface. We are, however, free in implementing our own custom **actions and features** and the way our data is being handled internally.\n",
    "\n",
    "In contrast to **REST** which uses **HTTP** for communication, **Arrow Flight** is built on top of gRPC. <br>\n",
    "Just like **Arrow** itself, **Arrow Flight** is also language-agnostic, <br>\n",
    "so you can develop clients in any language as long as it follows/supports the **Arrow Flight API** [4]. <br>\n",
    "\n",
    "In this tutorial, we are going to use Python to demonstrate client and server interactions. <br>\n",
    "First, let's start the server."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import subprocess\n",
    "import time\n",
    "\n",
    "SERVER_IP = \"localhost\"\n",
    "SERVER_PORT = \"5005\"\n",
    "\n",
    "server_process = subprocess.Popen([\"python3\",\"server.py\",\"--host\", SERVER_IP,\"--port\", SERVER_PORT])\n",
    "pid = server_process.pid\n",
    "time.sleep(2) # Wait for server to boot before running other cells"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The server is now running in the background as long as the notebook is active, i.e. its kernel is running. <br>\n",
    "Of course, you can also run it in a regular terminal if you want to read the console output, for example:\n",
    "\n",
    "`python3 server --host <HOST> --port <PORT>`\n",
    "\n",
    "For now, let's connect a client to the server and see how we can upload our local CSV file:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from RemoteArrow import RemoteDataset\n",
    "client_A = RemoteDataset(\"hawaii_covid.csv\", hostname=SERVER_IP+\":\"+SERVER_PORT)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Here, we have instantiated a **RemoteDataset** object with a path to the local CSV file and the server's address. <br>\n",
    "Under the hood, our object (**client_A**) converted that file into an **Arrow Table** (just as above) and sent it to the server via **doPut**.\n",
    "\n",
    "It does so without having to serialize or convert the data again. The server simply receives it in batches and reconstruct the **Arrow Table** from it.\n",
    "\n",
    "The dataset now resides on the server and is available to all clients as a **Flight** with **ID 0**. <br>\n",
    "\n",
    "You will also find that the server has stored our file in the ***/datasets*** subdirectory in **.parquet** format. <br>\n",
    "The **.parquet** format allows for highly memory-efficient compression, when writing or reading Arrow Tables. <br>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "client_A.list_flights()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "A **Flight** is nothing but an access point that corresponds to one dataset or data chunk. <br>\n",
    "A client may ask the server for all available Flights that it can access, i.e. download or query against. <br>\n",
    "\n",
    "Technically, a data chunk is also a \"dataset\" but for the sake of this tutorial we refer to original data (e.g. a CSV file) as **datasets** <br>\n",
    "and any temporarily generated data as **data chunks**, i.e. the result of a query. <br>\n",
    "In any event, both are internally handled as **Arrow Tables** and exposed as Flights.<br>\n",
    "\n",
    "Furthermore, instantiating **client_A** as a **RemoteDataset** also overrides the object's **Arrow Table methods** with corresponding RPC calls to our server. <br>\n",
    "What that means is that calling methods like **take** or **select**, as we did in the previous section above, <br>\n",
    "will not locally compute the query, but instead command the server to do the exact same query for us (on the dataset we just uploaded), <br>\n",
    "and return the result to us through the RPC channel. As mentioned before, it will also make the result available as a **Flight**.<br>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "query_result = client_A.take([0,1,2]) # Will be executed on the server, and the result saved in our local variable \"query_result\"\n",
    "query_result.to_pandas() "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Query results are made available as new Flights\n",
    "client_A.list_flights()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Until now, it may not be totally clear why this is useful, if we could just have computed the same query locally <br>\n",
    "without having to send it to the server first. But keep in mind that **client_A** may be much more restricted <br>\n",
    "in computational power or memory resources in comparison to our server. <br>\n",
    "\n",
    "Also we may now delete the dataset on **client_A** (both on disk and in runtime memory). <br>\n",
    "\n",
    "\n",
    "Now, let's pretend to be another client (**client_B**) and see how we can interact with one of the Flights. <br>\n",
    "We can **inspect()** a Flight first, to get insight on its metadata (e.g. *schema*, *num of rows*, ...)."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "client_B = RemoteDataset() # Instantiate client with default host (localhost:5005) and no file"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "client_B.inspect(0) # Inspect Flight 0\n",
    "client_B.connect(0) # Connect to Flight 0"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Connecting to a Flight means that all of our local calls are once again overriden with **RPC calls** <br>\n",
    "that command the server to do the queries against the dataset associated with that Flight."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "client_B.take([0,1,2,3,4,5]).to_pandas() # Call take() on Flight 0 and convert result to pandas"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Note that, **client_B** can now query against the original dataset (**hawaii_covid**) without ever downloading it. <br>\n",
    "\n",
    "This becomes incredibly efficient, when you want to query against a dataset that is extremly large, <br>\n",
    "or you simply don't want to download or store it in it's entirety. <br>\n",
    "\n",
    "One key aspect to understand, however, is that **only the first method call** that follows the RemoteDataset object (**client_B**), <br>\n",
    "invokes a remote procedure call. In the case above that means, only **client_B.take([0,1,2,3,4,5])** is being sent and processed by the server.<br>\n",
    "The result is being returned as an Arrow Table object and **locally** converted to a pandas dataframe. <br>\n",
    "\n",
    "\n",
    "If we want to download the entire dataset (or data chunk) of the Flight that our client is connected to, we can use **fetch()**."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "ds = client_B.fetch() # Download the entire dataset of the connected Flight and store the result in \"ds\"\n",
    "\n",
    "# Convert it to pandas dataframe and continue to process it locally\n",
    "df = ds.to_pandas()\n",
    "print(\"Original num of rows: \", len(df))\n",
    "\n",
    "dropped = df.dropna()\n",
    "print(\"Num of rows without nulls: \", len(dropped))\n",
    "\n",
    "dropped[\"case_month\"]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "As you can see, there is a lot of flexibility in switching between accessing local and shared datasets.<br>\n",
    "Making intermediate query results publicly available also creates an increased synergy between clients, <br>\n",
    "if they are working in the context of a larger application or system. <br>\n",
    "\n",
    "One client may upload a huge dataset, another can compute a bunch of queries against it and the third client has access to all of the results <br>\n",
    "and can cherry pick only the ones relevant to its task. In any case, we can eliminate redundancy and potentially boost performance and efficacy on all ends.\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Actions\n",
    "\n",
    "**Apache Arrow Flight** defines another interface to interact with Flights, so-called **Actions**. <br>\n",
    "Actions are application-specific commands. Our server provides Actions for **saving, deleting, and clearing Flights** as well as **shutting down the server**. <br>\n",
    "\n",
    "Any client can send actions by properly setting the action **type** and **body** (payload) that are defined by our server. <br>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "client_C = RemoteDataset()\n",
    "client_C.list_actions()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "client_C.action(type=\"save\", body=\"1 my_new_dataset\") # Request server to save Flight 1 as \"my_new_dataset.parquet\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "client_C.action(\"clear\") # Clear all flights (not affecting .parquet files)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "client_C.list_flights()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "All Flights have now been cleared and the list of available Flights is empty. <br>\n",
    "However, the files that have been saved should still be stored on our server. <br>\n",
    "\n",
    "Let's see what happens if our server crashes or reboots gracefully."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "client_C.action(\"shutdown\")\n",
    "time.sleep(5) # Wait for server to properly shutdown before running other cells"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Restart the server\n",
    "server_process = subprocess.Popen([\"python3\",\"server.py\",\"--host\", SERVER_IP,\"--port\", SERVER_PORT])\n",
    "pid = server_process.pid\n",
    "\n",
    "time.sleep(2) # Wait for server to boot\n",
    "client_D = RemoteDataset()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "You should see that the server recovered the saved datasets. <br>\n",
    "As a final step in this tutorial, we can delete them via the \"delete\" actions. The corresponding .parquet files will also be wiped from the server."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "client_D.action(\"delete\", \"0\")\n",
    "client_D.action(\"delete\", \"1\")\n",
    "\n",
    "client_D.list_flights()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Note that, the IDs did not disappear and were not rearranged, inorder to maintain consistency throughout the runtime of the server. <br>\n",
    "This is necessary when deleting specific Flights one by one, whereas \"clearing\" all Flights basically removes the necessity to maintain that order. <br>\n",
    "\n",
    "Of course you can implement many more actions, such as *deleting all files*, *renaming a file*, *rebooting the server*, *check server health*, etc., <br>\n",
    "the list is virtually endless, which underlines the versatility and extensability of **Arrow** and **Arrow Flight**."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Conclusion\n",
    "In this tutorial, we have examined how **Remote Arrow** can help to outsource the burden of computation, storage and shared access of data on a single server. <br>\n",
    "Though still in its prototype phase, it can offer tremendous flexibility for managing shared tabular data.<br>\n",
    "This effect becomes more evident when datasets are used in a network of heterogenous applications that work in different languages, <br>\n",
    "even more so when the shared data is extremely large and/or the clients low in computational prowess.\n",
    "\n",
    "Another aspect, we have not discussed in-depth yet is the remarkable boost in transmission speed, that has been benchmarked by *Ahmad et al.* [4]. <br>\n",
    "Their publication cites that *\"Flight is able to achieve up to **6000 MB/s and 4800 MB/s throughput**\"* <br>\n",
    "and companies like **Dremio** that use Arrow Flight **perform 20x and 30x better** compared to traditional connection methods. <br>\n",
    "That means Arrow Flight becomes an even better choice for applications that require long-haul communication over the internet. <br>\n",
    "\n",
    "### Limitations\n",
    "One major limitation is that the Remote Arrow server is a single-point of failure. <br>\n",
    "It is also synchronous and can only serve on request at a time, making it <br>\n",
    "suboptimal for high-frequency applications or systems that require massive scaling. <br>\n",
    "Some of these problems may be ameliorated by instantiating multiple servers and setting up a load-balancer between clients and servers. <br>\n",
    "This, however, comes at the cost of increased complexity for managing the shared data and handling asynchronous access and race conditions. <br>\n",
    "\n",
    "**Arrow Flight** is also still in its developing stage and thus not as stable or prevalent as more established frameworks for data transfers. <br>\n",
    "Moreover, the API and documentation is rather opaque and can be somewhat restrictive, where a lot of the development of **Remote Arrow** consisted of <br>\n",
    "workarounds and trial & error. However, we are confident that **Arrow** and **Arrow Flight** will find their way in becoming industry-standards as time progresses.\n",
    "\n",
    "\n",
    "### Future work\n",
    "If you're interested in contributing or developing your own application, please refer to the sources above and check out the Git repositories. <br>\n",
    "**Remote Arrow** could be extended by developing new actions, scrutinizing and benchmarking current features, as well as supporting different file formats. <br>\n",
    "Writing **Remote Arrow** clients in different languages would also be helpful, especially when testing it in an in-vivo multi-client system. <br>\n",
    "\n",
    "Regardless of the use-case, hopefully you have learned that **Arrow** especially in combination with **Arrow Flight** provides a highly performant framework for working with big data."
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.12 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}